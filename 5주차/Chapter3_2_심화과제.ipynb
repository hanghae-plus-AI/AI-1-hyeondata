{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanghae-plus-AI/AI-1-hyeondata/blob/main/Chapter3_2_%EC%8B%AC%ED%99%94%EA%B3%BC%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 목표\n",
        "\n",
        "---\n",
        "\n",
        "이번 과제에서는 2023년도 수능 국어 문제를 GPT-4로 풀어볼 것입니다. 아래 요구사항들을 지켜주시면 됩니다.\n",
        "\n",
        "- [ ]  수능 국어 문제를 준비합니다. 다음 github의 `data > 2023_11_KICE.json` data를 colab으로 불러오시면 됩니다:\n",
        "    \n",
        "    [GitHub - NomaDamas/KICE_slayer_AI_Korean: 수능 국어 1등급에 도전하는 AI](https://github.com/NomaDamas/KICE_slayer_AI_Korean)\n",
        "    \n",
        "- [ ]  하나의 문제에 대해서 GPT-4의 예측 결과를 내놓는 함수를 `def prediction(problem)`이라는 signature로 만드셔야 합니다. `problem`은 json 형태의 문제입니다. 내부는 logit 계산을 통해 구현하거나 순수하게 text 생성으로 해결하셔도 좋습니다. ***단, 2023년도 수능 국어의 정답을 활용하시면 안됩니다.***\n",
        "- [ ]  `def prediction` 함수를 모든 수능 국어 문제들에 대해서 돌린 후, 실제 정답과 비교하여 GPT-4의 점수를 계산하는 코드를 구현하시면 됩니다. ***단, 점수 계산은 모두 코드를 통해서만 진행되어야 합니다.*** 사람이 직접 GPT-4의 출력 결과를 보고 대조하는 형식으로 되면 안됩니다.\n",
        "- [ ]  채점 결과 50점을 넘기면 통과입니다."
      ],
      "metadata": {
        "id": "AwQvjh5FSVxJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "먼저 필요한 library들을 설치합니다."
      ],
      "metadata": {
        "id": "wUk08smFpXCJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3mIFZyNXwvP",
        "outputId": "e6a214ce-2763-4c5e-93d8-c9db8b86403c",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.51.2-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.14.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Downloading openai-1.51.2-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.7/383.7 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.0.1-py3-none-any.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, jiter, h11, dill, multiprocess, httpcore, httpx, openai, datasets\n",
            "Successfully installed datasets-3.0.1 dill-0.3.8 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.6.1 multiprocess-0.70.16 openai-1.51.2 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "그 다음 openai api key를 다음과 같은 절차를 거쳐 얻어냅니다:\n",
        "1. platform.openai.com 에 계정을 생성하여 로그인합니다.\n",
        "2. `Dashboard > API keys` 메뉴로 들어가 `+ Create new secret key`를 눌러줍니다.\n",
        "3. 이름을 작성한 후, `Create secret key`를 눌러 key를 만들어줍니다.\n",
        "4. 생성된 key를 복사한 후 아래 \"OPENAI_API_KEY\"에 불여넣어줍니다."
      ],
      "metadata": {
        "id": "qHSO087Gpj1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "client = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))"
      ],
      "metadata": {
        "id": "TuFFzx_TXxn3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음은 GPT api로 text 생성하는 예시입니다."
      ],
      "metadata": {
        "id": "xvLffQE1qWId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temperature = 0.5  # 각 token을 샘플링할 때 사용하는 temperature 값입니다.\n",
        "max_tokens = 4096  # 생성하는 최대 token 개수 입니다.\n",
        "n = 5  # 같은 질의에 대해 몇 개의 답변을 출력할지 결정합니다.\n",
        "frequency_penalty = 0.0  # 같은 단어가 반복적으로 나오는 것을 방지하기 위한 옵션입니다.\n",
        "user_prompt = \"List the subjects in Euclidean plane geometry.\"\n",
        "\n",
        "message=[{\"role\": \"user\", \"content\": user_prompt}]\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=message,\n",
        "    n=n,\n",
        "    max_tokens=max_tokens,\n",
        "    temperature=temperature,\n",
        "    frequency_penalty=frequency_penalty\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8g9L-5H_X3Ui",
        "outputId": "a893f999-66f3-474d-cb1c-752a0d039a5a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Euclidean plane geometry is a branch of mathematics that deals with the properties and relationships of points, lines, angles, and shapes in a two-dimensional plane. Here are some of the key subjects within Euclidean plane geometry:\n",
            "\n",
            "1. **Points and Lines**:\n",
            "   - Definition and properties of points and lines\n",
            "   - Line segments and rays\n",
            "   - Collinear and non-collinear points\n",
            "\n",
            "2. **Angles**:\n",
            "   - Types of angles (acute, right, obtuse, straight)\n",
            "   - Angle relationships (complementary, supplementary, adjacent, vertical)\n",
            "   - Angle bisectors\n",
            "\n",
            "3. **Triangles**:\n",
            "   - Types of triangles (equilateral, isosceles, scalene)\n",
            "   - Triangle congruence (SSS, SAS, ASA, AAS, HL)\n",
            "   - Triangle similarity (AA, SSS, SAS)\n",
            "   - Pythagorean theorem\n",
            "   - Properties of special triangles (e.g., 30-60-90, 45-45-90)\n",
            "\n",
            "4. **Quadrilaterals and Polygons**:\n",
            "   - Types of quadrilaterals (parallelogram, rectangle, square, rhombus, trapezoid)\n",
            "   - Properties and theorems related to quadrilaterals\n",
            "   - Sum of interior and exterior angles of polygons\n",
            "   - Regular polygons\n",
            "\n",
            "5. **Circles**:\n",
            "   - Parts of a circle (radius, diameter, circumference, arc, chord, sector)\n",
            "   - Properties of tangents and secants\n",
            "   - Inscribed and central angles\n",
            "   - Arcs and chords\n",
            "\n",
            "6. **Transformations**:\n",
            "   - Translation, rotation, reflection, and dilation\n",
            "   - Properties of transformations\n",
            "   - Symmetry\n",
            "\n",
            "7. **Coordinate Geometry**:\n",
            "   - The Cartesian coordinate system\n",
            "   - Distance and midpoint formulas\n",
            "   - Slope of a line\n",
            "   - Equation of a line (slope-intercept, point-slope, standard form)\n",
            "\n",
            "8. **Area and Perimeter**:\n",
            "   - Formulas for the area and perimeter of various shapes (triangles, rectangles, circles, etc.)\n",
            "   - Heron's formula for the area of a triangle\n",
            "\n",
            "9. **Constructions**:\n",
            "   - Basic geometric constructions using a compass and straightedge\n",
            "   - Constructing angles, perpendicular bisectors, and parallel lines\n",
            "\n",
            "10. **Loci and Conic Sections**:\n",
            "    - Definition and properties of loci\n",
            "    - Basic introduction to conic sections (ellipse, parabola, hyperbola) in the plane\n",
            "\n",
            "These subjects form the foundation of Euclidean plane geometry and are typically covered in high school geometry courses.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prediction() : 수능 국어 예측 함수 제작\n",
        "\n",
        "https://github.com/NomaDamas/KICE_slayer_AI_Korean 에서\n",
        "3. zero-shot-CoT 영어\n",
        "2번의 zero-shot-CoT와 내용은 동일하나, 프롬프트의 언어가 미치는 영향을 분석하기 위하여 instruction 및 프롬프트를 영어로 작성한 프롬프트입니다.\n",
        "\n",
        "를 이용해서 점수를 예측해 본 코드입니다"
      ],
      "metadata": {
        "id": "alG3_jvdWiTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "# from openai import OpenAI\n",
        "from tqdm import tqdm\n",
        "# GPT-4 매개변수 설정\n",
        "# TEMPERATURE = 0.5\n",
        "# MAX_TOKENS = 4096\n",
        "# N = 1\n",
        "# FREQUENCY_PENALTY = 0.0\n",
        "MODEL = \"gpt-4o\"  # 사용할 모델\n",
        "def prediction(problem):\n",
        "\n",
        "    prompt = f\"다음은 한국의 대학수학능력시험 국어 문제입니다. 가장 적절한 답을 선택하세요.\\n\\n\"\n",
        "\n",
        "    if 'paragraph' in problem:\n",
        "        prompt += f\"지문:\\n{problem['paragraph']}\\n\\n\"\n",
        "\n",
        "    prompt += f\"문제: {problem['question']}\\n\\n\"\n",
        "\n",
        "    if 'question_plus' in problem:\n",
        "        prompt += f\"추가 정보: {problem['question_plus']}\\n\\n\"\n",
        "\n",
        "    prompt += \"선택지:\\n\"\n",
        "    for i, choice in enumerate(problem['choices'], 1):\n",
        "        prompt += f\"{i}. {choice}\\n\"\n",
        "    prompt += \"\\n답변은 1부터 5 사이의 숫자로만 해주세요.\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"\"\"As a smart student answer the given question.\n",
        "Read paragraph, and select only one answer between 5 choices.\n",
        "\"\"\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            n=1,\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature,\n",
        "            frequency_penalty=frequency_penalty\n",
        "        )\n",
        "\n",
        "        # 응답에서 숫자만 추출\n",
        "        prediction = ''.join(filter(str.isdigit, response.choices[0].message.content))\n",
        "        prediction = int(prediction) if prediction else 0\n",
        "\n",
        "        # 1부터 5 사이의 숫자로 제한\n",
        "        return max(1, min(5, prediction))\n",
        "    except Exception as e:\n",
        "        print(f\"Error in prediction: {e}\")\n",
        "        return 0\n"
      ],
      "metadata": {
        "id": "wcEEVtEljLgV"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### calculate_score() : 점수 계산 함수"
      ],
      "metadata": {
        "id": "Jq6V2CNSWth4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_score(predictions, answers, scores):\n",
        "    total_score = 0\n",
        "    for pred, ans, score in zip(predictions, answers, scores):\n",
        "        if pred == ans:\n",
        "            total_score += score\n",
        "    return total_score"
      ],
      "metadata": {
        "id": "V556i0MDS1jn"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 수능 국어 문제 json파일인 2023_11_KICE.json을 가져와서 문제 예측"
      ],
      "metadata": {
        "id": "juOs1Ap0XRSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# JSON 파일 읽기\n",
        "try:\n",
        "    with open('/content/2023_11_KICE.json', 'r', encoding='utf-8') as file:\n",
        "        data = json.load(file)\n",
        "except Exception as e:\n",
        "    print(f\"Error reading JSON file: {e}\")\n",
        "    exit(1)\n",
        "\n",
        "# 모든 문제에 대해 예측 실행\n",
        "predictions = []\n",
        "answers = []\n",
        "scores = []\n",
        "\n",
        "for item in tqdm(data):\n",
        "    for problem in item['problems']:\n",
        "        pred = prediction(problem) # 수능 국어 예측 함수에 문제 넣어서 예측\n",
        "        predictions.append(pred)\n",
        "        answers.append(problem['answer'])\n",
        "        scores.append(problem['score'])\n",
        "\n",
        "# 점수 계산\n",
        "total_score = calculate_score(predictions, answers, scores)\n",
        "\n",
        "print(f\"총 문제 수: {len(answers)}\")\n",
        "print(f\"GPT-4o 점수: {total_score}\")\n",
        "print(f\"만점: {sum(scores)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ue3CILYFTH_6",
        "outputId": "25236f9e-bdb3-4536-a800-126c7d40128b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:31<00:00,  2.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 문제 수: 45\n",
            "GPT-4o 점수: 64\n",
            "만점: 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPT-4o를 사용했을 경우 점수는 64점을 보여준다."
      ],
      "metadata": {
        "id": "gxKd8MZPXgRp"
      }
    }
  ]
}